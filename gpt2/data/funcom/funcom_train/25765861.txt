TDAT: private void tokenise ( document doc ) {  <NL> try {  <NL> locale locale = get locale ( ) ;  <NL> sentence splitter splitter = sentence splitter . get instance ( locale ) ;  <NL> splitter . set text ( doc . get text ( ) ) ;  <NL> while ( splitter . has next ( ) ) {  <NL> sentence sentence = splitter . next ( ) ;  <NL> doc . get sentences ( ) . add ( sentence ) ;  <NL> doc . get tokens ( ) . add all ( sentence . get tokens ( ) ) ;  <NL>  }  <NL>  } catch ( throwable e ) {  <NL> throw new repository exception ( document _ parsing _ error , " error during tokenising of document ' " + doc . get name ( ) + " ' . " , e ) ;  <NL>  }  <NL>  }  COM: <s> extract sentences and their tokens </s>